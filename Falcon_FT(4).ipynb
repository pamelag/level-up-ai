{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ/7NY9gmzHkhIfmaIOycC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pamelag/level-up-ai/blob/main/Falcon_FT(4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOsRBfBHd_Z2"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pip\n",
        "!pip install bitsandbytes\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install peft\n",
        "!pip install accelerate\n",
        "!pip install datasets\n",
        "!pip install loralib\n",
        "!pip install einops"
      ],
      "metadata": {
        "id": "I6VRhgOoeMj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow==15.0.0"
      ],
      "metadata": {
        "id": "g8r7QTikeUN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from pprint import pprint\n",
        "\n",
        "import bitsandbytes as bnb\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import notebook_login\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    PeftModel,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        ")\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "metadata": {
        "id": "BTJy0bjZecEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "LDdTKtiZef9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1u85RQZdRTmpjGKcCc5anCMAHZ-um4DUC"
      ],
      "metadata": {
        "id": "Dp_nZ1lPej2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"delivery-plan-faq-new.json\") as json_file:\n",
        "    data = json.load(json_file)"
      ],
      "metadata": {
        "id": "RFv-lQkkemdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "9M9eVfWSepql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"delivery-plan-faq-new.json\", \"w\") as f:\n",
        "    json.dump(data, f)"
      ],
      "metadata": {
        "id": "A8zj0y__esN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data).head()"
      ],
      "metadata": {
        "id": "wxkk65aJevuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"tiiuae/falcon-7b\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "-_HcKjcleyV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "2VTjPaB2e2UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "TBqaibhFe6K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "C18CWz10fBhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        ": Strategy & Innovation team is working on Data Insights and Actions under Digital and Customer Identity strategic Program and Embrace Innovation strategic Focus Area. The initiative lead of Digital Identity is Mimi, Director, Strategy & Innovation. High Level Actions under this initiative is to Implement the capture, use & storage of Tax File Number (TFN) as a unique identifier for customers in property transactions. Major Milestones - Commonwealth legislative amendments commenced to enable Revenue NSW's use of TFNs to administer property related taxes, grants and schemes. Developed collateral for the Interjurisdictional Working Group to implement the proposal with a consistent and considered approach Completed artefacts supporting TFN proposal for NSW and commenced implementation preparations.\n",
        ":\n",
        "\"\"\".strip()\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "ER3ANaqXfCoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 200\n",
        "generation_config.temperature = 0.7\n",
        "generation_config.top_p = 0.7\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "id": "NMcCtbXkfFwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config"
      ],
      "metadata": {
        "id": "OrDZlXuAfJjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "device = \"cuda:0\"\n",
        "\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "# with torch.inference_mode():\n",
        "outputs = model.generate(\n",
        "    input_ids=encoding.input_ids,\n",
        "    attention_mask=encoding.attention_mask,\n",
        "    generation_config=generation_config,\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "VbjvFttNfPYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(\"json\", data_files=\"delivery-plan-faq-new.json\")"
      ],
      "metadata": {
        "id": "pBF4PvvTfQhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "nQBCs9WGfT2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"train\"][0]"
      ],
      "metadata": {
        "id": "b6L2yoErfYyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(data_point):\n",
        "    return f\"\"\"\n",
        ": {data_point[\"question\"]}\n",
        ": {data_point[\"answer\"]}\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def generate_and_tokenize_prompt(data_point):\n",
        "    full_prompt = generate_prompt(data_point)\n",
        "    tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n",
        "    return tokenized_full_prompt"
      ],
      "metadata": {
        "id": "-17MmSgffbjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)"
      ],
      "metadata": {
        "id": "xepbGdoBf6Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "vsOH1af1f6_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = \"experiments\""
      ],
      "metadata": {
        "id": "ngTbNfeVf9x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = transformers.TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    save_total_limit=3,\n",
        "    logging_steps=1,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    max_steps=100,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.05,\n",
        ")\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=data,\n",
        "    args=training_args,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "model.config.use_cache = False\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "MS2llHHOf_kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"trained-model\")"
      ],
      "metadata": {
        "id": "2bAYWDpWgByv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = PeftConfig.from_pretrained(\"trained-model\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    return_dict=True,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = PeftModel.from_pretrained(model, \"trained-model\")"
      ],
      "metadata": {
        "id": "Fg8JNmlhgGhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 200\n",
        "generation_config.temperature = 0.7\n",
        "generation_config.top_p = 0.7\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "id": "-kHHj1yWgLVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda:0\""
      ],
      "metadata": {
        "id": "d2viHhpFgNs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "prompt = f\"\"\"\n",
        ": Strategy & Innovation team is working on Data Insights and Actions under Digital and Customer Identity strategic Program and Embrace Innovation strategic Focus Area. The initiative lead of Digital Identity is Mimi, Director, Strategy & Innovation. High Level Actions under this initiative is to Implement the capture, use & storage of Tax File Number (TFN) as a unique identifier for customers in property transactions. Major Milestones - Commonwealth legislative amendments commenced to enable Revenue NSW's use of TFNs to administer property related taxes, grants and schemes. Developed collateral for the Interjurisdictional Working Group to implement the proposal with a consistent and considered approach Completed artefacts supporting TFN proposal for NSW and commenced implementation preparations.\n",
        ":\n",
        "\"\"\".strip()\n",
        "\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "kQ-FGstsgOmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(question: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        ": {question}\n",
        ":\n",
        "\"\"\".strip()\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "    with torch.inference_mode():\n",
        "        outputs = model.generate(\n",
        "            input_ids=encoding.input_ids,\n",
        "            attention_mask=encoding.attention_mask,\n",
        "            generation_config=generation_config,\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    assistant_start = \":\"\n",
        "    response_start = response.find(assistant_start)\n",
        "    return response[response_start + len(assistant_start) :].strip()"
      ],
      "metadata": {
        "id": "g0g6xxx2gRIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Strategy & Innovation team is working on Data Insights and Actions under Digital and Customer Identity strategic Program and Embrace Innovation strategic Focus Area. The initiative lead of Digital Identity is Jocelyn Yem, Director, Strategy & Innovation. High Level Actions under this initiative is to Implement the capture, use & storage of Tax File Number (TFN) as a unique identifier for customers in property transactions. Major Milestones - Commonwealth legislative amendments commenced to enable Revenue NSW's use of TFNs to administer property related taxes, grants and schemes. Developed collateral for the Interjurisdictional Working Group to implement the proposal with a consistent and considered approach Completed artefacts supporting TFN proposal for NSW and commenced implementation preparations.\"\n",
        "print(generate_response(prompt))"
      ],
      "metadata": {
        "id": "Kg1Y_DfFgUza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Optimisation and Project Delivery team is working on Improved Accessibility as part of Being Responsive to our Customers Aspire Initiative under Supporting our diverse customers Program and passionate customer focus strategic Focus Area. The initiative lead of Being Responsive to our Customers is Sharon Bicknell, Director, Optimisation and Project Delivery. High Level Actions under this initiative is Expand & improve accessibility to the Work and Development Order program. Major Milestones - Completed discovery and design.,Confirmed acceptance of discovery and design recommendations, Developed implementation plan, Implemented recommendations.\"\n",
        "print(generate_response(prompt))"
      ],
      "metadata": {
        "id": "A4dnW2V9gXhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Technical Advisory Services team is working on Implement new structure for prosecutions & valuations program as part of Improved Integrity Aspire Initiative under Future Fit Workforce strategic Program and Collect, Protect, Enable Focus Area. The initiative lead of Transparent options to support customers is Cullen Smythe, Executive Director, Technical Advisory Services. High Level Action for this initiative is to Implement new structure for prosecutions & valuations. Major Milestones - Delivered an uplift in staff capability in prosecutions and valuations through delivery of training and cascading of new skill set, Confirmed procurement of an expert valuer\"\n",
        "\n",
        "print(generate_response(prompt))"
      ],
      "metadata": {
        "id": "BVfJY73ggaVb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}