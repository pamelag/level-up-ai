{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgriXzjQxUDBHsktWG7Usc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pamelag/level-up-ai/blob/main/ll_FT(1)ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-whE_rHAu0oy"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install peft\n",
        "!pip install bitsandbytes\n",
        "!pip install trl"
      ],
      "metadata": {
        "id": "6hiq7cJdu8pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from huggingface_hub import notebook_login\n",
        "from peft import LoraConfig, PeftModel\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from trl import SFTTrainer\n",
        "\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\""
      ],
      "metadata": {
        "id": "OIvMN5Dgu-fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "Ihg5O20uvBr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"json\", data_files=\"delivery-plan-faq-new.json\")"
      ],
      "metadata": {
        "id": "QN4sS3bCvDmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "jF4GjjbcvFg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "gC6UH6cBvHQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
        "You are a professional writer. Rewrite the following text in simple words.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def generate_training_prompt(\n",
        "    question: str, answer: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
        ") -> str:\n",
        "    return f\"\"\"### Instruction: {system_prompt}\n",
        "\n",
        "### Input:\n",
        "{question.strip()}\n",
        "\n",
        "### Response:\n",
        "{answer}\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "paGBvJTSvOkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"@[^\\s]+\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return re.sub(r\"\\^[^ ]+\", \"\", text)"
      ],
      "metadata": {
        "id": "OHYJWNV9vQsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(data_point):\n",
        "    print(data_point)\n",
        "    question = data_point[\"question\"]\n",
        "    answer = data_point[\"answer\"]\n",
        "\n",
        "    return {\n",
        "      \"question\": question,\n",
        "      \"answer\": answer,\n",
        "      \"text\": generate_training_prompt(question, answer),\n",
        "    }"
      ],
      "metadata": {
        "id": "-jhwxERfvS0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "oIugnK3JvU2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = generate_text(dataset[\"train\"][0])"
      ],
      "metadata": {
        "id": "eYSELvI4vXGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(example[\"text\"])"
      ],
      "metadata": {
        "id": "JmDxkx7-vclZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset(data: Dataset):\n",
        "    return (\n",
        "        data.shuffle(seed=42)\n",
        "        .map(generate_text)\n",
        "    )"
      ],
      "metadata": {
        "id": "U0UuBthfve0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"] = process_dataset(dataset[\"train\"])"
      ],
      "metadata": {
        "id": "C6vMLF5VviqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "A-euhCwwvk88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_and_tokenizer():\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        use_safetensors=True,\n",
        "        quantization_config=bnb_config,\n",
        "        trust_remote_code=True,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"right\"\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "fYZOxXrPvnZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = create_model_and_tokenizer()\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "lWrEkw6HvqUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.quantization_config.to_dict()"
      ],
      "metadata": {
        "id": "KfnsJ4xjvspF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_r = 16\n",
        "lora_alpha = 64\n",
        "lora_dropout = 0.1\n",
        "lora_target_modules = [\n",
        "    \"q_proj\",\n",
        "    \"up_proj\",\n",
        "    \"o_proj\",\n",
        "    \"k_proj\",\n",
        "    \"down_proj\",\n",
        "    \"gate_proj\",\n",
        "    \"v_proj\",\n",
        "]\n",
        "\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=lora_r,\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    target_modules=lora_target_modules,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "dRSIMzvPvv9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = \"experiments\"\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    logging_steps=1,\n",
        "    learning_rate=1e-4,\n",
        "    fp16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    num_train_epochs=2,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=0.2,\n",
        "    warmup_ratio=0.05,\n",
        "    save_strategy=\"epoch\",\n",
        "    group_by_length=True,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    save_safetensors=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    seed=42,\n",
        ")"
      ],
      "metadata": {
        "id": "LTh7emjAvyiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        ")"
      ],
      "metadata": {
        "id": "VXlDi3knv6Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "GdjxYevCv9xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "id": "_ChXTgJvwACo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "3R0II4u4wGt5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}