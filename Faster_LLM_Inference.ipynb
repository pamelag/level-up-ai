{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi1VkNlAnWGZarLa+aOYtp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pamelag/level-up-ai/blob/main/Faster_LLM_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9kUd-EBMuXV"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pip\n",
        "!pip install bitsandbytes\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install peft\n",
        "!pip install datasets\n",
        "!pip install loralib\n",
        "!pip install einops"
      ],
      "metadata": {
        "id": "NgemLcFMM0Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftConfig, PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
      ],
      "metadata": {
        "id": "8AnCeOfNM2AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-7b\", padding_side=\"left\")\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "-bSCJJp4M43Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda:0\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        ": Digital Products Digital Taxes is working on developing a roadmap for customer identity requirements as part of Single identity for Customers Aspire Initiative under Digital and Customer Identity strategic Program and passionate customer focus strategic Focus Area. The initiative lead of Digital Identity is Dan Papallo, Director, Digital Products Digital Taxes. High Level Actions under this initiative is Understand and develop a roadmap for customer identity requirements across all of Revenue NSW. Major Milestones - Define the unified and holistic view of Revenue NSW customer identity across multiple touchpoints and products, Develop an implementation roadmap,Complete implementation of Revenue Identity Management Service (phase 1), Develop and release Property Data Service proof of concept.Develop customer grouping initial solution.\n",
        ":\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "encoding = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)"
      ],
      "metadata": {
        "id": "NNDQCDsBM6zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")"
      ],
      "metadata": {
        "id": "QYCQ4IpGM9uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = PeftConfig.from_pretrained(\"trained-model\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    return_dict=True,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = PeftModel.from_pretrained(model, \"trained-model\")"
      ],
      "metadata": {
        "id": "MxsTfaLANCXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = model.generation_config\n",
        "generation_config.max_new_tokens = 250\n",
        "generation_config.temperature = 0\n",
        "generation_config.num_return_sequences = 1\n",
        "generation_config.pad_token_id = tokenizer.eos_token_id\n",
        "generation_config.eos_token_id = tokenizer.eos_token_id"
      ],
      "metadata": {
        "id": "x4otWx6bNHEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -r 5\n",
        "\n",
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "        do_sample=False,\n",
        "        use_cache=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "uJjsTvFjNIDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "    outputs = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        generation_config=generation_config,\n",
        "        do_sample=False,\n",
        "        use_cache=True,\n",
        "    )\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "IFyEJsJZNLIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    bnb_8bit_use_double_quant=True,\n",
        "    bnb_8bit_quant_type=\"nf8\",\n",
        "    bnb_8bit_compute_dtype=torch.bfloat16,\n",
        ")"
      ],
      "metadata": {
        "id": "kBABICfLNNhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = PeftConfig.from_pretrained(\"trained-model\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    return_dict=True,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    load_in_8bit_fp32_cpu_offload=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = PeftModel.from_pretrained(model, \"trained-model\")"
      ],
      "metadata": {
        "id": "Zq2-3JIYNPZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = PeftConfig.from_pretrained(\"trained-model\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    return_dict=True,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    load_in_8bit=True,\n",
        ")\n",
        "\n",
        "model = PeftModel.from_pretrained(model, MODEL_ID)"
      ],
      "metadata": {
        "id": "MEohndk_NReS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}